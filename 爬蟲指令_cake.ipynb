{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e36bbaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\miles10601\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\miles10601\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (4.14.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\miles10601\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\miles10601\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (3.1.5)\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.38.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\miles10601\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\miles10601\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\miles10601\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miles10601\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in c:\\users\\miles10601\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\miles10601\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\miles10601\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\miles10601\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\miles10601\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\miles10601\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\miles10601\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Collecting trio<1.0,>=0.31.0 (from selenium)\n",
      "  Downloading trio-0.32.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting websocket-client<2.0,>=1.8.0 (from selenium)\n",
      "  Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting attrs>=23.2.0 (from trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sortedcontainers (from trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cffi>=1.14 (from trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading cffi-2.0.0-cp314-cp314-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Downloading wsproto-1.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3.0,>=2.5.0->selenium)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\miles10601\\appdata\\roaming\\python\\python314\\site-packages (from webdriver-manager) (25.0)\n",
      "Collecting pycparser (from cffi>=1.14->trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\miles10601\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting h11<1,>=0.16.0 (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Downloading selenium-4.38.0-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/9.7 MB 11.4 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.0/9.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.0/9.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.3/9.7 MB 1.7 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.6/9.7 MB 1.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 1.8/9.7 MB 1.5 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 1.8/9.7 MB 1.5 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.1/9.7 MB 1.3 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.4/9.7 MB 1.3 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 2.4/9.7 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.6/9.7 MB 1.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.9/9.7 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.1/9.7 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.1/9.7 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 3.4/9.7 MB 1.1 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 3.7/9.7 MB 1.1 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 3.7/9.7 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 3.9/9.7 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.2/9.7 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 4.5/9.7 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 4.5/9.7 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 4.7/9.7 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.0/9.7 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.0/9.7 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.2/9.7 MB 1.0 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.2/9.7 MB 1.0 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 5.5/9.7 MB 1.0 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 5.8/9.7 MB 995.6 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.0/9.7 MB 998.9 kB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.3/9.7 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.3/9.7 MB 1.0 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 6.6/9.7 MB 1.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 6.8/9.7 MB 987.2 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 6.8/9.7 MB 987.2 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 7.1/9.7 MB 984.5 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 7.3/9.7 MB 988.5 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 7.6/9.7 MB 982.4 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 7.6/9.7 MB 982.4 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 7.9/9.7 MB 975.3 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.1/9.7 MB 970.8 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.1/9.7 MB 970.8 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.4/9.7 MB 970.2 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.7/9.7 MB 970.9 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 8.9/9.7 MB 967.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.9/9.7 MB 967.9 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.2/9.7 MB 969.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.7 MB 965.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.7 MB 965.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 955.2 kB/s  0:00:09\n",
      "Downloading trio-0.32.0-py3-none-any.whl (512 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading cffi-2.0.0-cp314-cp314-win_amd64.whl (185 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.3.2-py3-none-any.whl (24 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, websocket-client, sniffio, python-dotenv, pysocks, pycparser, h11, attrs, wsproto, webdriver-manager, outcome, cffi, trio, trio-websocket, selenium\n",
      "\n",
      "   -- -------------------------------------  1/15 [websocket-client]\n",
      "   -- -------------------------------------  1/15 [websocket-client]\n",
      "   -- -------------------------------------  1/15 [websocket-client]\n",
      "   -- -------------------------------------  1/15 [websocket-client]\n",
      "   ----- ----------------------------------  2/15 [sniffio]\n",
      "   -------- -------------------------------  3/15 [python-dotenv]\n",
      "   ---------- -----------------------------  4/15 [pysocks]\n",
      "   ------------- --------------------------  5/15 [pycparser]\n",
      "   ------------- --------------------------  5/15 [pycparser]\n",
      "   ---------------- -----------------------  6/15 [h11]\n",
      "   ---------------- -----------------------  6/15 [h11]\n",
      "   ------------------ ---------------------  7/15 [attrs]\n",
      "   ------------------ ---------------------  7/15 [attrs]\n",
      "   --------------------- ------------------  8/15 [wsproto]\n",
      "   ------------------------ ---------------  9/15 [webdriver-manager]\n",
      "   ------------------------ ---------------  9/15 [webdriver-manager]\n",
      "   -------------------------- ------------- 10/15 [outcome]\n",
      "   ----------------------------- ---------- 11/15 [cffi]\n",
      "   ----------------------------- ---------- 11/15 [cffi]\n",
      "   ----------------------------- ---------- 11/15 [cffi]\n",
      "   -------------------------------- ------- 12/15 [trio]\n",
      "   -------------------------------- ------- 12/15 [trio]\n",
      "   -------------------------------- ------- 12/15 [trio]\n",
      "   -------------------------------- ------- 12/15 [trio]\n",
      "   -------------------------------- ------- 12/15 [trio]\n",
      "   -------------------------------- ------- 12/15 [trio]\n",
      "   -------------------------------- ------- 12/15 [trio]\n",
      "   -------------------------------- ------- 12/15 [trio]\n",
      "   -------------------------------- ------- 12/15 [trio]\n",
      "   -------------------------------- ------- 12/15 [trio]\n",
      "   -------------------------------- ------- 12/15 [trio]\n",
      "   -------------------------------- ------- 12/15 [trio]\n",
      "   -------------------------------- ------- 12/15 [trio]\n",
      "   -------------------------------- ------- 12/15 [trio]\n",
      "   ---------------------------------- ----- 13/15 [trio-websocket]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ------------------------------------- -- 14/15 [selenium]\n",
      "   ---------------------------------------- 15/15 [selenium]\n",
      "\n",
      "Successfully installed attrs-25.4.0 cffi-2.0.0 h11-0.16.0 outcome-1.3.0.post0 pycparser-2.23 pysocks-1.7.1 python-dotenv-1.2.1 selenium-4.38.0 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.32.0 trio-websocket-0.12.2 webdriver-manager-4.0.2 websocket-client-1.9.0 wsproto-1.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wsdump.exe is installed in 'c:\\Users\\miles10601\\AppData\\Local\\Programs\\Python\\Python314\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script dotenv.exe is installed in 'c:\\Users\\miles10601\\AppData\\Local\\Programs\\Python\\Python314\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas openpyxl selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a82b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "啟動瀏覽器搜尋：資料工程師，預計抓取 1 頁...\n",
      "  -> 正在讀取第 1 頁: https://www.cake.me/jobs?q=資料工程師&page=1\n",
      "     第 1 頁找到 10 筆新職缺 (目前累計: 10)\n",
      "\n",
      "開始逐筆抓取詳細資料並分析內文技能...\n",
      "[1/10] 分析中: https://www.cake.me/companies/commeet/jobs/data-assistant-engineerdata-science-intern\n",
      "[2/10] 分析中: https://www.cake.me/companies/pinkoi/jobs/b2ec807e-05ce-449b-bd06-42404466362d-data-engineer-10e1700edfb1a970396752254773d1\n",
      "[3/10] 分析中: https://www.cake.me/companies/7-eleven-vietnam/jobs/data-engineer-intern-b66\n",
      "[4/10] 分析中: https://www.cake.me/companies/WorldQuant/jobs/4607049006-data-engineer-8207e93ed0b79a6e5296899e2822d0\n",
      "[5/10] 分析中: https://www.cake.me/companies/opennet-limited/jobs/data-engineer-99f\n",
      "[6/10] 分析中: https://www.cake.me/companies/WorldQuant/jobs/4329394006-senior-data-engineer-fd4904f48a6d46e057cf48beed7c19\n",
      "[7/10] 分析中: https://www.cake.me/companies/Google/jobs/120947988674552518-senior-data-engineer-youtube-b2162348c9f8a6da1a3301ea7cdac7\n",
      "[8/10] 分析中: https://www.cake.me/companies/Google/jobs/109015621412233926-technical-solutions-data-engineer-data-and-analyt-98d0e094832777de78f6ad2d838906\n",
      "[9/10] 分析中: https://www.cake.me/companies/logitech/jobs/877113581c871000995fd78804410000-audio-ml-data-engineer-2799633eb6fc5b66591f1954e01bc1\n",
      "[10/10] 分析中: https://www.cake.me/companies/logitech/jobs/23ee80b2ebea1001951d644a4e990000-l4b-senior-data-engineer-84cb39d0e4857208903e81e8416f47\n",
      "\n",
      "成功！資料已儲存至: Cake_資料工程師_含技能分析_test.xlsx\n",
      "\n",
      "=== 技能需求統計 (Top 10) ===\n",
      "python: 9 次\n",
      "git: 4 次\n",
      "sql: 4 次\n",
      "kubernetes: 3 次\n",
      "shell: 3 次\n",
      "mysql: 2 次\n",
      "spark: 2 次\n",
      "aws: 2 次\n",
      "linux: 2 次\n",
      "tableau: 2 次\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Selenium 相關套件\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# =========================================================\n",
    "# 設定：資料工程師常見技能關鍵字詞庫 (用於內文掃描分析)\n",
    "# =========================================================\n",
    "# 您可以自由擴充這個列表\n",
    "DATA_ENGINEER_KEYWORDS = [\n",
    "    # 程式語言\n",
    "    \"python\", \"java\", \"scala\", \"go\", \"golang\", \"r\", \"c++\", \"c#\", \"sql\", \"nosql\",\n",
    "    # 資料庫 & 倉儲\n",
    "    \"mysql\", \"postgresql\", \"postgres\", \"mongodb\", \"redis\", \"cassandra\", \n",
    "    \"oracle\", \"sql server\", \"bigquery\", \"redshift\", \"snowflake\", \"dynamodb\",\n",
    "    # 大數據 & 處理框架\n",
    "    \"spark\", \"hadoop\", \"kafka\", \"flink\", \"hive\", \"hbase\", \"airflow\", \"dbt\", \n",
    "    \"pandas\", \"numpy\", \"databricks\", \"presto\", \"trino\",\n",
    "    # 雲端平台\n",
    "    \"aws\", \"azure\", \"gcp\", \"google cloud\", \"aliyun\",\n",
    "    # DevOps & 工具\n",
    "    \"docker\", \"kubernetes\", \"k8s\", \"git\", \"jenkins\", \"gitlab\", \"linux\", \"bash\", \"shell\",\n",
    "    \"terraform\", \"ansible\",\n",
    "    # BI & 視覺化\n",
    "    \"tableau\", \"power bi\", \"looker\", \"superset\"\n",
    "]\n",
    "\n",
    "def extract_skills_from_content(text):\n",
    "    \"\"\"\n",
    "    從工作內容的一大段文字中，掃描是否包含特定技能關鍵字\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    found_skills = []\n",
    "    \n",
    "    for keyword in DATA_ENGINEER_KEYWORDS:\n",
    "        # 使用正規表達式避免抓到單字的一部分 (例如避免把 'mysql' 抓成 'sql')\n",
    "        # \\b 代表單字邊界\n",
    "        pattern = r\"(?:^|\\W)\" + re.escape(keyword) + r\"(?:$|\\W)\"\n",
    "        if re.search(pattern, text_lower):\n",
    "            found_skills.append(keyword)\n",
    "            \n",
    "    return \", \".join(found_skills) # 回傳逗號分隔的字串\n",
    "\n",
    "# =========================================================\n",
    "# 1. 核心邏輯：單頁資料抓取\n",
    "# =========================================================\n",
    "def safe_get_text(tag):\n",
    "    return tag.get_text(strip=True) if tag else None\n",
    "\n",
    "def match_any(text, keywords):\n",
    "    return any(k in text for k in keywords)\n",
    "\n",
    "def get_job_details(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)\"}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # --- Breadcrumbs ---\n",
    "    breadcrumbs = [bc.get_text(strip=True) \n",
    "                   for bc in soup.find_all(class_=re.compile(\"Breadcrumbs_labelText\"))]\n",
    "    # 預設為 None，可自動 fallback \n",
    "    job_title = company = industry = category = None \n",
    "    if len(breadcrumbs) >= 4: \n",
    "        # 正常情況 index 結構為： \n",
    "        # 0=首頁, 1=公司, 2=公司名稱, 3=產業, 4=職務類別, 5=職務名稱 \n",
    "        job_title = breadcrumbs[2] \n",
    "        company = breadcrumbs[1] \n",
    "        industry = breadcrumbs[3] \n",
    "        category = breadcrumbs[4]\n",
    "\n",
    "    # --- 更新時間 ---\n",
    "    updated_date = None\n",
    "    for lab in soup.find_all(\"div\", class_=re.compile(\"InlineMessage_label\")):\n",
    "        txt = safe_get_text(lab)\n",
    "        if txt and (\"更新\" in txt):\n",
    "            updated_date = txt\n",
    "            break\n",
    "\n",
    "    # --- 工作內容 (含技能分析) ---\n",
    "    content_sections = soup.find_all(\"div\", class_=\"RailsHtml_container__LlMcK\")\n",
    "    content_text = \"\\n\".join([c.get_text(\"\\n\", strip=True) for c in content_sections])\n",
    "    \n",
    "    # *** 新增：從內文分析技能 ***\n",
    "    skills_from_content = extract_skills_from_content(content_text)\n",
    "\n",
    "    # --- 右側資訊 ---\n",
    "    job_info_container = soup.find(\"div\", class_=re.compile(\"JobDescriptionRightColumn_jobInfo\"))\n",
    "\n",
    "    job_data = {\n",
    "        \"職缺名稱\": job_title,\n",
    "        \"公司名稱\": company,\n",
    "        \"產業類別\": industry,\n",
    "        \"職務類別\": category,\n",
    "        \"職缺連結\": url,\n",
    "        \"更新時間\": updated_date,\n",
    "        \"職務型態\": \"未標示\",\n",
    "        \"職務等級\": \"未標示\",\n",
    "        \"招募人數\": \"未標示\",\n",
    "        \"地點\": None,\n",
    "        \"薪資\": None,\n",
    "        \"經驗\": \"經驗不拘\",\n",
    "        \"管理責任\": \"不需負擔管理責任\",\n",
    "        \"遠端工作\": \"不支援遠端\",\n",
    "        \"其他標籤(右側欄)\": \"\",       # 網站原本標示的 tag\n",
    "        \"技能工具(內文分析)\": skills_from_content, # 我們自己分析出的\n",
    "        \"工作內容\": content_text,\n",
    "    }\n",
    "\n",
    "    if job_info_container:\n",
    "        rows = job_info_container.find_all(\"div\", recursive=False)\n",
    "        for row in rows:\n",
    "            text = safe_get_text(row)\n",
    "            if not text: continue\n",
    "\n",
    "            if match_any(text, [\"全職\", \"兼職\", \"實習\", \"Contract\", \"派遣\"]):\n",
    "                parts = text.split(\"・\")\n",
    "                job_data[\"職務型態\"] = parts[0]\n",
    "                if len(parts) > 1: job_data[\"職務等級\"] = parts[1]\n",
    "            elif row.find(class_=re.compile(\"locationsWrapper\")):\n",
    "                job_data[\"地點\"] = text\n",
    "            elif match_any(text, [\"TWD\", \"USD\", \"月薪\", \"年薪\", \"時薪\"]) and any(c.isdigit() for c in text):\n",
    "                job_data[\"薪資\"] = text\n",
    "            elif \"經驗\" in text or \"year\" in text.lower():\n",
    "                job_data[\"經驗\"] = text\n",
    "            elif \"管理\" in text:\n",
    "                job_data[\"管理責任\"] = text\n",
    "            elif \"遠端\" in text or \"Remote\" in text:\n",
    "                job_data[\"遠端工作\"] = text\n",
    "            elif (text.isdigit() or \"人\" in text) and len(text) < 10:\n",
    "                if \"管理\" not in text:\n",
    "                    number_match = re.search(r\"(\\d+)\", text)\n",
    "                    if number_match: job_data[\"招募人數\"] = number_match.group(1)\n",
    "            elif row.find(\"a\"):\n",
    "                job_data[\"其他標籤(右側欄)\"] = row.get_text(separator=\", \", strip=True)\n",
    "\n",
    "    return job_data\n",
    "\n",
    "# =========================================================\n",
    "# 2. 列表抓取：改為分頁模式 (Page Pagination)\n",
    "# =========================================================\n",
    "def get_job_links_by_page(keyword, max_pages=3):\n",
    "    \"\"\"\n",
    "    透過 URL 參數 &page=1, &page=2 進行翻頁抓取\n",
    "    \"\"\"\n",
    "    print(f\"啟動瀏覽器搜尋：{keyword}，預計抓取 {max_pages} 頁...\")\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    # chrome_options.add_argument(\"--headless\") # 開發時建議先註解掉，看得到瀏覽器比較安心\n",
    "    \n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    \n",
    "    base_url = \"https://www.cake.me/jobs\"\n",
    "    job_links = []\n",
    "    seen_urls = set()\n",
    "\n",
    "    for page in range(1, max_pages + 1):\n",
    "        # 組合分頁網址\n",
    "        target_url = f\"{base_url}?q={keyword}&page={page}\"\n",
    "        print(f\"  -> 正在讀取第 {page} 頁: {target_url}\")\n",
    "        \n",
    "        driver.get(target_url)\n",
    "        time.sleep(4) # 等待頁面載入 (Cake 載入速度中等，建議給 3-5 秒)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        \n",
    "        # 抓取該頁所有職缺連結\n",
    "        atags = soup.find_all(\"a\", href=re.compile(r\"/companies/.+/jobs/\"))\n",
    "        \n",
    "        new_links_count = 0\n",
    "        for a in atags:\n",
    "            href = a.get(\"href\")\n",
    "            if not href.startswith(\"http\"):\n",
    "                full_url = \"https://www.cake.me\" + href\n",
    "            else:\n",
    "                full_url = href\n",
    "            \n",
    "            if full_url not in seen_urls:\n",
    "                job_links.append(full_url)\n",
    "                seen_urls.add(full_url)\n",
    "                new_links_count += 1\n",
    "            if \"no job found\" in safe_get_text(a).lower():\n",
    "                # 如果看到「找不到職缺」的訊息，表示沒有更多職缺了\n",
    "                print(\"    找不到更多職缺，提前結束抓取。\")\n",
    "                driver.quit()\n",
    "                return job_links\n",
    "        \n",
    "        print(f\"     第 {page} 頁找到 {new_links_count} 筆新職缺 (目前累計: {len(job_links)})\")\n",
    "\n",
    "    driver.quit()\n",
    "    return job_links\n",
    "\n",
    "# =========================================================\n",
    "# 3. 主程式\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    keyword = \"資料工程師\"\n",
    "    MAX_PAGES = 1  # 您可以設定要抓幾頁，例如 5 或 10\n",
    "    \n",
    "    # A. 抓取連結\n",
    "    links = get_job_links_by_page(keyword, max_pages=MAX_PAGES)\n",
    "    \n",
    "    all_jobs_data = []\n",
    "\n",
    "    # B. 抓取細節\n",
    "    print(\"\\n開始逐筆抓取詳細資料並分析內文技能...\")\n",
    "    for index, link in enumerate(links):\n",
    "        print(f\"[{index+1}/{len(links)}] 分析中: {link}\")\n",
    "        \n",
    "        details = get_job_details(link)\n",
    "        if details:\n",
    "            all_jobs_data.append(details)\n",
    "        \n",
    "        time.sleep(random.uniform(1.5, 3)) # 禮貌性延遲\n",
    "\n",
    "    # C. 匯出與簡單統計\n",
    "    if all_jobs_data:\n",
    "        df = pd.DataFrame(all_jobs_data)\n",
    "        \n",
    "        # 欄位排序\n",
    "        columns_order = [\n",
    "            \"職缺名稱\", \"公司名稱\", \"地點\", \"薪資\", \"經驗\", \n",
    "            \"技能工具(內文分析)\", \"其他標籤(右側欄)\", # 將技能欄位往前放\n",
    "            \"職務型態\", \"職務等級\", \"招募人數\", \"管理責任\", \"遠端工作\", \n",
    "            \"更新時間\", \"產業類別\", \"職務類別\", \"職缺連結\", \"工作內容\"\n",
    "        ]\n",
    "        final_cols = [c for c in columns_order if c in df.columns]\n",
    "        df = df[final_cols]\n",
    "\n",
    "        filename = f\"Cake_{keyword}_含技能分析_test.xlsx\"\n",
    "        df.to_excel(filename, index=False, engine=\"openpyxl\")\n",
    "        print(f\"\\n成功！資料已儲存至: {filename}\")\n",
    "        \n",
    "        # --- 額外功能：顯示最熱門的技能 ---\n",
    "        print(\"\\n=== 技能需求統計 (Top 10) ===\")\n",
    "        all_skills = []\n",
    "        for skills_str in df[\"技能工具(內文分析)\"]:\n",
    "            if skills_str:\n",
    "                all_skills.extend(skills_str.split(\", \"))\n",
    "        \n",
    "        if all_skills:\n",
    "            counter = Counter(all_skills)\n",
    "            for skill, count in counter.most_common(10):\n",
    "                print(f\"{skill}: {count} 次\")\n",
    "        else:\n",
    "            print(\"未分析到任何技能關鍵字。\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\n沒有抓取到任何資料。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
